{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f66b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\work\\\\project mlops\\\\Chatbot1\\\\Chatbot'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea3e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1d512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\work\\project mlops\\Chatbot1\\Chatbot\n"
     ]
    }
   ],
   "source": [
    "cd Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d56190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\work\\\\project mlops\\\\Chatbot1\\\\Chatbot'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edc33ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Columns in dataset: ['input_ids', 'attention_mask', 'labels']\n",
      "üìä First example:\n",
      " Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 50000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load any one batch (e.g., tokenized_batch_1)\n",
    "dataset = load_from_disk(\"artifacts/data_transformation/train/train_tokenized_batch_1\")\n",
    "\n",
    "print(\"üìÅ Columns in dataset:\", dataset.column_names)\n",
    "print(\"üìä First example:\\n\", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ea97bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          input_text  \\\n",
      "0                       'content':'', 'role': 'user'   \n",
      "1  'content': 'what does it mean when an individu...   \n",
      "2  'content': 'what is the smallest c++ json pars...   \n",
      "3  'content': 'hace un resumen diciendo de que se...   \n",
      "4  'content': 'create a mutual fund portfolio for...   \n",
      "5                   'content': '20,', 'role': 'user'   \n",
      "6  'content':'Create short Google Ads compelling ...   \n",
      "7  'content': '1. \"Mengapa Tunggu Lagi? Beli Seka...   \n",
      "8  'content':'Create short Google Ads compelling ...   \n",
      "9  'content': 'Write a tweet announcing NAME_1, a...   \n",
      "\n",
      "                                         target_text  \n",
      "0  'content':'    .         .  , ,  .           ....  \n",
      "1  'content': \"When an individual says they want ...  \n",
      "2  'content': 'One of the smallest C++ JSON parse...  \n",
      "3  'content': 'La transcripci√≥n est√° hablando sob...  \n",
      "4  'content': 'Certainly! Here is a mutual fund p...  \n",
      "5  'content': 'Sure. Here's a Python code to gene...  \n",
      "6  'content': '1. \"Mengapa Tunggu Lagi? Beli Seka...  \n",
      "7  'content':'Create short Google Ads compelling ...  \n",
      "8  'content': '1. \"Belanja Sekarang Berbagi Kebah...  \n",
      "9  'content': '\"Introducing NAME_1, the latest ad...  \n",
      "‚úÖ Saved decoded data to decoded_batch_1.csv\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ‚úÖ Load tokenizer and dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "dataset = load_from_disk(\"artifacts/data_transformation/train/train_tokenized_batch_1\")\n",
    "\n",
    "# ‚úÖ Decode token IDs back into text\n",
    "decoded_inputs = [tokenizer.decode(ids, skip_special_tokens=True) for ids in dataset[\"input_ids\"]]\n",
    "decoded_labels = [tokenizer.decode(ids, skip_special_tokens=True) for ids in dataset[\"labels\"]]\n",
    "\n",
    "# ‚úÖ Convert to DataFrame for inspection\n",
    "df = pd.DataFrame({\n",
    "    \"input_text\": decoded_inputs,\n",
    "    \"target_text\": decoded_labels\n",
    "})\n",
    "\n",
    "# ‚úÖ Show sample\n",
    "print(df.head(10))\n",
    "\n",
    "# ‚úÖ Optional: Save for manual viewing\n",
    "df.to_csv(\"decoded_batch_1.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"‚úÖ Saved decoded data to decoded_batch_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'content':'', 'role': 'user'</td>\n",
       "      <td>'content':'    .         .  , ,  .           ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'content': 'what does it mean when an individu...</td>\n",
       "      <td>'content': \"When an individual says they want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'content': 'what is the smallest c++ json pars...</td>\n",
       "      <td>'content': 'One of the smallest C++ JSON parse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'content': 'hace un resumen diciendo de que se...</td>\n",
       "      <td>'content': 'La transcripci√≥n est√° hablando sob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'content': 'create a mutual fund portfolio for...</td>\n",
       "      <td>'content': 'Certainly! Here is a mutual fund p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0                       'content':'', 'role': 'user'   \n",
       "1  'content': 'what does it mean when an individu...   \n",
       "2  'content': 'what is the smallest c++ json pars...   \n",
       "3  'content': 'hace un resumen diciendo de que se...   \n",
       "4  'content': 'create a mutual fund portfolio for...   \n",
       "\n",
       "                                         target_text  \n",
       "0  'content':'    .         .  , ,  .           ....  \n",
       "1  'content': \"When an individual says they want ...  \n",
       "2  'content': 'One of the smallest C++ JSON parse...  \n",
       "3  'content': 'La transcripci√≥n est√° hablando sob...  \n",
       "4  'content': 'Certainly! Here is a mutual fund p...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column([[3, 2, 31, 14819, 31, 10, 3, 31, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 3, 2, 3, 2, 3, 2, 6, 3, 2, 3, 2, 6, 3, 2, 3, 2, 3, 2, 5, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 2, 29, 2, 29, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 6, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 3, 2, 3, 2, 3, 1], [3, 2, 31, 14819, 31, 10, 96, 10555, 46, 928, 845, 79, 241, 12, 253, 1730, 42, 2530, 16, 70, 280, 6, 79, 33, 3, 21008, 3, 9, 3667, 12, 734, 70, 6831, 11, 70, 1075, 16, 8, 296, 5, 100, 960, 21, 1730, 557, 5806, 8, 826, 3149, 10, 2, 29, 2, 29, 5411, 3, 23393, 53, 2620, 11, 11393, 10, 2449, 164, 2762, 12, 734, 125, 79, 124, 81, 167, 11, 125, 9314, 70, 3055, 11, 2874, 5, 100, 54, 7789, 6990, 525, 2620, 6, 11393, 6, 11, 4854, 7, 12, 482, 3, 9, 1254, 13, 12866, 11, 576, 760, 1433, 16, 70, 1342, 5, 2, 29, 4416, 14490, 2987, 11, 3984, 10, 2449, 164, 960, 21, 1087, 42, 4120, 24, 29444, 70, 2987, 6, 1], [3, 2, 31, 14819, 31, 10, 3, 31, 10723, 13, 8, 3, 17924, 205, 16702, 446, 10466, 260, 7, 277, 19, 96, 565, 6644, 1280, 94, 19, 3, 9, 205, 16702, 2596, 446, 10466, 3595, 24, 19, 10182, 11, 514, 12, 169, 5, 94, 54, 36, 261, 12, 260, 7, 15, 321, 446, 10466, 11, 446, 10466, 345, 6166, 11, 7216, 5, 2351, 677, 19, 96, 29, 40, 32, 107, 2434, 87, 354, 739, 1686, 84, 19, 3, 9, 13956, 18, 9926, 205, 16702, 446, 10466, 3595, 24, 19, 876, 12, 36, 422, 6, 650, 6, 11, 514, 12, 169, 5, 31, 6, 3, 31, 3491, 15, 31, 10, 3, 31, 6500, 7, 3672, 31, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 2, 31, 14819, 31, 10, 3, 31, 3612, 3017, 2685, 102, 12765, 259, 2975, 9809, 40, 232, 32, 78, 1999, 50, 12480, 20, 3, 1931, 3466, 23, 15742, 96, 634, 2126, 121, 3, 63, 2629, 3, 154, 226, 23, 235, 3, 63, 212, 2, 26, 9, 3, 35, 50, 3, 107, 17905, 20, 50, 7, 576, 8172, 7, 3, 1931, 3466, 6823, 7, 5, 325, 12480, 369, 29, 172, 4922, 975, 73, 4301, 235, 3, 195, 9, 11374, 32, 96, 2962, 10812, 15, 3152, 7, 121, 3, 35, 3, 15, 40, 3, 9, 2, 32, 2766, 6, 3, 63, 29928, 297, 15, 142, 22664, 52, 17, 23, 4922, 3, 35, 73, 9, 12480, 20, 3, 1931, 3466, 23, 15742, 238, 142, 259, 1536, 4922, 3, 35, 1], [3, 2, 31, 14819, 31, 10, 3, 31, 22243, 55, 947, 19, 3, 9, 8543, 3069, 4833, 21, 2768, 1020, 28, 3, 9, 5354, 1201, 20752, 24, 963, 1442, 827, 11, 533, 124, 8981, 10, 2, 29, 5411, 4480, 11010, 9273, 6394, 3611, 262, 9164, 41, 553, 5494, 61, 3, 18, 100, 262, 9164, 6542, 8, 821, 13, 8, 1297, 837, 1519, 512, 11, 65, 3, 9, 731, 8225, 5688, 13, 3, 11739, 5170, 5, 2, 29, 4416, 22822, 448, 180, 184, 345, 2899, 262, 9164, 5313, 41, 4274, 476, 61, 3, 18, 100, 262, 9164, 6542, 8, 821, 13, 8, 180, 184, 345, 2899, 5538, 11, 65, 3, 9, 731, 8225, 5688, 13, 3, 11739, 7561, 5, 2, 29, 5787, 3, 23, 24501, 7, 5266, 3597, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d6ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
